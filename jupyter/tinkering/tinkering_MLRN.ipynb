{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lamb optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Lamb optimizer.\"\"\"\n",
    "\n",
    "import collections\n",
    "import math\n",
    "\n",
    "import torch\n",
    "from tensorboardX import SummaryWriter\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "def log_lamb_rs(optimizer: Optimizer, event_writer: SummaryWriter, token_count: int):\n",
    "    \"\"\"Log a histogram of trust ratio scalars in across layers.\"\"\"\n",
    "    results = collections.defaultdict(list)\n",
    "    for group in optimizer.param_groups:\n",
    "        for p in group['params']:\n",
    "            state = optimizer.state[p]\n",
    "            for i in ('weight_norm', 'adam_norm', 'trust_ratio'):\n",
    "                if i in state:\n",
    "                    results[i].append(state[i])\n",
    "\n",
    "    for k, v in results.items():\n",
    "        event_writer.add_histogram(f'lamb/{k}', torch.tensor(v), token_count)\n",
    "\n",
    "class Lamb(Optimizer):\n",
    "    r\"\"\"Implements Lamb algorithm.\n",
    "\n",
    "    It has been proposed in `Large Batch Optimization for Deep Learning: Training BERT in 76 minutes`_.\n",
    "\n",
    "    Arguments:\n",
    "        params (iterable): iterable of parameters to optimize or dicts defining\n",
    "            parameter groups\n",
    "        lr (float, optional): learning rate (default: 1e-3)\n",
    "        betas (Tuple[float, float], optional): coefficients used for computing\n",
    "            running averages of gradient and its square (default: (0.9, 0.999))\n",
    "        eps (float, optional): term added to the denominator to improve\n",
    "            numerical stability (default: 1e-8)\n",
    "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
    "        adam (bool, optional): always use trust ratio = 1, which turns this into\n",
    "            Adam. Useful for comparison purposes.\n",
    "\n",
    "    .. _Large Batch Optimization for Deep Learning: Training BERT in 76 minutes:\n",
    "        https://arxiv.org/abs/1904.00962\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-6,\n",
    "                 weight_decay=0, adam=False):\n",
    "        if not 0.0 <= lr:\n",
    "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
    "        if not 0.0 <= eps:\n",
    "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
    "        if not 0.0 <= betas[0] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
    "        if not 0.0 <= betas[1] < 1.0:\n",
    "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
    "                        weight_decay=weight_decay)\n",
    "        self.adam = adam\n",
    "        super(Lamb, self).__init__(params, defaults)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        \"\"\"Performs a single optimization step.\n",
    "\n",
    "        Arguments:\n",
    "            closure (callable, optional): A closure that reevaluates the model\n",
    "                and returns the loss.\n",
    "        \"\"\"\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('Lamb does not support sparse gradients, consider SparseAdam instad.')\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                # State initialization\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    # Exponential moving average of gradient values\n",
    "                    state['exp_avg'] = torch.zeros_like(p.data)\n",
    "                    # Exponential moving average of squared gradient values\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p.data)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                state['step'] += 1\n",
    "\n",
    "                # Decay the first and second moment running average coefficient\n",
    "                # m_t\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "                # v_t\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "\n",
    "                # Paper v3 does not use debiasing.\n",
    "                # bias_correction1 = 1 - beta1 ** state['step']\n",
    "                # bias_correction2 = 1 - beta2 ** state['step']\n",
    "                # Apply bias to lr to avoid broadcast.\n",
    "                step_size = group['lr'] # * math.sqrt(bias_correction2) / bias_correction1\n",
    "\n",
    "                weight_norm = p.data.pow(2).sum().sqrt()#.clamp(0, 10)\n",
    "\n",
    "                adam_step = exp_avg / exp_avg_sq.sqrt().add(group['eps'])\n",
    "                if group['weight_decay'] != 0:\n",
    "                    adam_step.add_(group['weight_decay'], p.data)\n",
    "\n",
    "                adam_norm = adam_step.pow(2).sum().sqrt()\n",
    "                trust_ratio = weight_norm / adam_norm.add(1e-6) #trying to fix NaN (assuming it is caused by div0 here)\n",
    "                state['weight_norm'] = weight_norm\n",
    "                state['adam_norm'] = adam_norm\n",
    "                state['trust_ratio'] = trust_ratio\n",
    "                if self.adam:\n",
    "                    trust_ratio = 1\n",
    "\n",
    "                p.data.add_(-step_size * trust_ratio, adam_step)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "dataset_name = 'neutral'#'interpolation'\n",
    "if len(sys.argv) < 2:\n",
    "    print(\"Missing data path!\")\n",
    "    exit()\n",
    "\n",
    "datapath = os.path.join(sys.argv[1], dataset_name)\n",
    "datapath_preprocessed = os.path.join(sys.argv[1], dataset_name+'_preprocessed')\n",
    "\n",
    "os.mkdir(datapath_preprocessed)\n",
    "\n",
    "all_data = os.listdir(datapath)\n",
    "\n",
    "for filename in all_data:\n",
    "    with np.load(os.path.join(datapath, filename)) as data:\n",
    "        image = data['image'].astype(np.uint8).reshape(16, 160, 160)[:,::2,::2]\n",
    "        target = data['target']\n",
    "        np.savez_compressed(os.path.join(datapath_preprocessed, filename), image=image, target=target)\n",
    "\n",
    "print('Done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train_mixed_precision_distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'apex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-39821e9c0f73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mapex\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mapex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistributedDataParallel\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mDDP\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# from lamb import Lamb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'apex'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from apex import amp\n",
    "from apex.parallel import DistributedDataParallel as DDP\n",
    "# from lamb import Lamb\n",
    "\n",
    "#tensorboard for accuracy graphs\n",
    "import tensorflow as tf\n",
    "\n",
    "def getCombinations(inputTensor, N, c, d):#input shape=(batch_size, obj_count, obj_dim) #batch_size=N, obj_count=c, obj_dim=d\n",
    "    tensorA = inputTensor.reshape(N, 1, c, d).expand(N, c, c, d)\n",
    "    tensorB = tensorA.transpose(1, 2)\n",
    "\n",
    "    return torch.cat((tensorB, tensorA), 3)\n",
    "\n",
    "dataset_name = 'neutral'#'interpolation'#'extrapolation'\n",
    "\n",
    "\n",
    "if len(sys.argv) < 2:\n",
    "    print(\"Missing data path!\")\n",
    "    exit()\n",
    "\n",
    "datapath_preprocessed = os.path.join(sys.argv[1], dataset_name + '_preprocessed')\n",
    "\n",
    "class PgmDataset(Dataset):\n",
    "    def __init__(self, filenames):\n",
    "        'Initialization'\n",
    "        self.filenames = filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.filenames[index]\n",
    "        with np.load(os.path.join(datapath_preprocessed, filename)) as data:\n",
    "            image = data['image'].astype(np.uint8).reshape(16, 80, 80)\n",
    "            target = data['target']\n",
    "        return image, target\n",
    "\n",
    "class WReN(torch.nn.Module):\n",
    "    def __init__(self, m):\n",
    "        super(WReN, self).__init__()\n",
    "        self.relation_network_depth = m\n",
    "\n",
    "        self.g_dim = 512\n",
    "        self.h_dim = 256\n",
    "        self.f_dim = 256\n",
    "\n",
    "        self.use_mag_enc = True #switch between scalar input and magnitude encoded input\n",
    "        self.mag_enc_type_relu = False #switch between gaussian magnitude encoding and relu based magnitude encoding\n",
    "\n",
    "        self.magnitude_encoding_dim = 20\n",
    "        #model\n",
    "        #magnitude encoding\n",
    "        self.input_scale = 2.0/255.0\n",
    "        self.input_offset = -1.0\n",
    "        std_dev = 0.28\n",
    "        self.input_encoding_variance_inv = 1.0 / (math.sqrt(2.0) * std_dev)\n",
    "        self.normalization_factor = 1.0 / (math.sqrt(2*math.pi) * std_dev)\n",
    "        self.mag_scale = torch.nn.Parameter(torch.linspace(-1.0, 1.0, steps=self.magnitude_encoding_dim), requires_grad=False)\n",
    "\n",
    "        if self.use_mag_enc:\n",
    "            conv_input_dim = self.magnitude_encoding_dim\n",
    "        else:\n",
    "            conv_input_dim = 1\n",
    "\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(conv_input_dim, 32, 3, stride=2), \n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=2), \n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=2), \n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=2), \n",
    "            torch.nn.LeakyReLU()\n",
    "        )\n",
    "        self.post_cnn_linear = torch.nn.Linear(32*4*4, 256-9)\n",
    "\n",
    "        self.tag_matrix = torch.nn.Parameter(torch.eye(9).repeat(8, 1), requires_grad=False)\n",
    "\n",
    "        self.g = torch.nn.Sequential(\n",
    "                torch.nn.Linear(2*256, self.g_dim), \n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(self.g_dim, self.g_dim), \n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(self.g_dim, self.g_dim), \n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(self.g_dim, self.h_dim),\n",
    "                torch.nn.LeakyReLU()\n",
    "            )\n",
    "\n",
    "        h = []\n",
    "        for i in range(m):\n",
    "            rel_layer_func = torch.nn.Sequential(\n",
    "                torch.nn.Linear(2*self.h_dim, self.h_dim), \n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(self.h_dim, self.h_dim), \n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(self.h_dim, self.h_dim), \n",
    "                torch.nn.LeakyReLU()\n",
    "            )\n",
    "            h.append(rel_layer_func)\n",
    "\n",
    "        self.h = torch.nn.ModuleList(h)\n",
    "\n",
    "        f_in_dim = self.h_dim\n",
    "        self.f = torch.nn.Sequential(\n",
    "                torch.nn.Linear(f_in_dim, self.f_dim), \n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(self.f_dim, self.f_dim), \n",
    "                torch.nn.LeakyReLU()\n",
    "            )\n",
    "\n",
    "        self.f_final = torch.nn.Linear(self.f_dim, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, batch):\n",
    "        batch_size = batch.size()[0]\n",
    "        #Panel preprocessor CNN\n",
    "        batch_flat = batch.reshape(batch_size*16, 1, 80, 80)\n",
    "\n",
    "        if self.use_mag_enc:\n",
    "            with torch.no_grad():\n",
    "                #magnitude encoding\n",
    "                batch_flat = batch_flat.transpose(1, 3)\n",
    "                if self.mag_enc_type_relu:\n",
    "                    #first order\n",
    "                    batch_flat = batch_flat.add_(255/self.magnitude_encoding_dim)\n",
    "                    batch_flat = torch.nn.functional.relu_(batch_flat.mul_(self.input_scale).add_(self.input_offset).add(-self.mag_scale))\n",
    "                    #second order\n",
    "                    batch_flat = torch.cat((batch_flat[:, :, :, :-1] - 2*batch_flat[:, :, :, 1:], batch_flat[:, :, :, -1].unsqueeze(dim=-1)), dim=-1).mul_(self.magnitude_encoding_dim/2)\n",
    "                    batch_flat = torch.nn.functional.relu_(batch_flat)\n",
    "                else:\n",
    "                    batch_flat = batch_flat.mul_(self.input_scale).add_(self.input_offset).tanh_().add(self.mag_scale).mul_(self.input_encoding_variance_inv).pow_(2).mul_(-1).exp_().mul_(self.normalization_factor)\n",
    "                batch_flat = batch_flat.transpose(3, 1)\n",
    "\n",
    "        conv_out = self.conv(batch_flat)\n",
    "        #scatter context\n",
    "        objectsWithoutPos = self.post_cnn_linear(conv_out.reshape(batch_size*16, -1))\n",
    "        panel_vectors = objectsWithoutPos.reshape(batch_size, 16, 256-9)\n",
    "        given, option1, option2, option3, option4, option5, option6, option7, option8 = panel_vectors.split((8, 1, 1, 1, 1, 1, 1, 1, 1), dim=1)\n",
    "        optionsWithContext = torch.cat((\n",
    "            given, option1, \n",
    "            given, option2, \n",
    "            given, option3, \n",
    "            given, option4, \n",
    "            given, option5, \n",
    "            given, option6, \n",
    "            given, option7, \n",
    "            given, option8\n",
    "        ), 1)\n",
    "        optionsWithoutPos = optionsWithContext.reshape(batch_size*8*9, 256-9)\n",
    "\n",
    "        objects = torch.cat((optionsWithoutPos, self.tag_matrix.repeat(batch_size, 1)), dim=1).reshape(batch_size*8, 9, 256-9+9)\n",
    "\n",
    "        #MLRN\n",
    "        objPairs2D = getCombinations(objects, batch_size*8, 9, 256)\n",
    "        objPairs = objPairs2D.reshape(batch_size*8*(9*9), 2*256)\n",
    "\n",
    "        gResult = self.g(objPairs)#apply MLP\n",
    "\n",
    "        prev_result = gResult\n",
    "        prev_dim = self.h_dim\n",
    "        prev_result_2d = prev_result.reshape(batch_size*8, 9, 9, prev_dim)\n",
    "        sum_j = prev_result_2d.sum(dim=2)\n",
    "        for i, h_layer in enumerate(self.h):\n",
    "            residual = sum_j\n",
    "            intermed_obj_pairs_2d = getCombinations(sum_j, batch_size*8, 9, prev_dim)\n",
    "            intermed_obj_pairs = intermed_obj_pairs_2d.reshape(batch_size*8*(9*9), 2*prev_dim)\n",
    "            prev_result = h_layer(intermed_obj_pairs)#apply MLP\n",
    "            prev_dim = self.h_dim\n",
    "            prev_result_2d = prev_result.reshape(batch_size*8, 9, 9, prev_dim)\n",
    "            sum_j = prev_result_2d.sum(dim=2)\n",
    "\n",
    "        hSum = sum_j.sum(dim=1)\n",
    "        result = self.f_final(self.f(hSum))#pre-softmax scores for every possible answer\n",
    "\n",
    "        answer = result.reshape(batch_size, 8)\n",
    "\n",
    "        #attempt to stabilize training (avoiding inf value activations in last layers) \n",
    "        activation_loss = hSum.pow(2).mean() + result.pow(2).mean()\n",
    "\n",
    "        return answer, activation_loss\n",
    "\n",
    "def worker_fn(rank, world_size):\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    weights_filename = \"weights.pt\"\n",
    "    batch_size = 512\n",
    "    epochs = 240\n",
    "    warmup_epochs = 8\n",
    "    use_mixed_precision = True\n",
    "\n",
    "    batch_size = batch_size // world_size #batch size per worker\n",
    "\n",
    "    #Data\n",
    "    all_data = os.listdir(datapath_preprocessed)\n",
    "    train_filenames = [p for p in all_data if re.match(r'^PGM_' + re.escape(dataset_name) + r'_train_(\\d+)\\.npz$', p) is not None]\n",
    "    val_filenames = [p for p in all_data if re.match(r'^PGM_' + re.escape(dataset_name) + r'_val_(\\d+)\\.npz$', p) is not None]\n",
    "    train_dataset = PgmDataset(train_filenames)\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size, num_workers=8, pin_memory=False, sampler=train_sampler)#shuffle is done by the sampler\n",
    "    val_dataloader = DataLoader(PgmDataset(val_filenames), batch_size=batch_size, shuffle=False, num_workers=4, pin_memory=False)\n",
    "\n",
    "    #Model\n",
    "    device_ids = [rank]\n",
    "\n",
    "    model = WReN(2).to(device_ids[0])#3-layer MLRN\n",
    "\n",
    "    if weights_filename is not None and os.path.isfile(\"./\" + weights_filename):\n",
    "        model.load_state_dict(torch.load(weights_filename, map_location='cpu'))\n",
    "        print('Weights loaded')\n",
    "        cold_start = False\n",
    "    else:\n",
    "        print('No weights found')\n",
    "        cold_start = True\n",
    "\n",
    "    #Loss and optimizer\n",
    "    final_lr = 2e-3\n",
    "\n",
    "    def add_module_params_with_decay(module, weight_decay, param_groups):#adds parameters with decay unless they are bias parameters, which shouldn't receive decay\n",
    "        group_with_decay = []\n",
    "        group_without_decay = []\n",
    "        for name, param in module.named_parameters():\n",
    "            if not param.requires_grad: continue\n",
    "            if name == 'bias' or name.endswith('bias'):\n",
    "                group_without_decay.append(param)\n",
    "            else:\n",
    "                group_with_decay.append(param)\n",
    "        param_groups.append({\"params\": group_with_decay, \"weight_decay\": weight_decay})\n",
    "        param_groups.append({\"params\": group_without_decay})\n",
    "\n",
    "    optimizer_param_groups = [\n",
    "    ]\n",
    "\n",
    "    add_module_params_with_decay(model.conv, 2e-1, optimizer_param_groups)\n",
    "    add_module_params_with_decay(model.post_cnn_linear, 2e-1, optimizer_param_groups)\n",
    "    add_module_params_with_decay(model.g, 2e-1, optimizer_param_groups)\n",
    "    add_module_params_with_decay(model.h, 2e-1, optimizer_param_groups)\n",
    "    add_module_params_with_decay(model.f, 2e-1, optimizer_param_groups)\n",
    "    add_module_params_with_decay(model.f_final, 2e-1, optimizer_param_groups)\n",
    "\n",
    "    optimizer = Lamb(optimizer_param_groups, lr=final_lr)\n",
    "\n",
    "    base_model = model\n",
    "    if use_mixed_precision:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\") #Mixed Precision\n",
    "\n",
    "    lossFunc = torch.nn.CrossEntropyLoss()\n",
    "    softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "    #Parallel distributed model\n",
    "    device = device_ids[0]\n",
    "    torch.cuda.set_device(device)\n",
    "    parallel_model = torch.nn.parallel.DistributedDataParallel(model, device_ids)\n",
    "\n",
    "    if rank == 0:\n",
    "        #accuracy logging\n",
    "        sess = tf.Session()\n",
    "        train_acc_placeholder = tf.placeholder(tf.float32, shape=())\n",
    "        train_acc_summary = tf.summary.scalar('training_acc', train_acc_placeholder)\n",
    "        val_acc_placeholder = tf.placeholder(tf.float32, shape=())\n",
    "        val_acc_summary = tf.summary.scalar('validation_acc', val_acc_placeholder)\n",
    "        writer = tf.summary.FileWriter(\"log\", sess.graph)\n",
    "\n",
    "    #training loop\n",
    "    acc = []\n",
    "    global_step = 0\n",
    "    for epoch in range(epochs): \n",
    "        train_sampler.set_epoch(epoch) \n",
    "\n",
    "        # Validation\n",
    "        val_acc = []\n",
    "        parallel_model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, (local_batch, local_labels) in enumerate(val_dataloader):\n",
    "                local_batch, targets = local_batch.to(device), local_labels.to(device)\n",
    "\n",
    "                #answer = model(local_batch.type(torch.float32))\n",
    "                answer, _ = parallel_model(local_batch.type(torch.float32))\n",
    "\n",
    "                #Calc accuracy\n",
    "                answerSoftmax = softmax(answer)\n",
    "                maxIndex = answerSoftmax.argmax(dim=1)\n",
    "\n",
    "                correct = maxIndex.eq(targets)\n",
    "                accuracy = correct.type(dtype=torch.float16).mean(dim=0)\n",
    "                val_acc.append(accuracy)\n",
    "\n",
    "                if i % 50 == 0 and rank == 0:\n",
    "                    print(\"batch \" + str(i))\n",
    "\n",
    "        total_val_acc = sum(val_acc) / len(val_acc)\n",
    "        print('Validation accuracy: ' + str(total_val_acc.item()))\n",
    "        if rank == 0:\n",
    "            summary = sess.run(val_acc_summary, feed_dict={val_acc_placeholder: total_val_acc.item()})\n",
    "            writer.add_summary(summary, global_step=global_step)\n",
    "\n",
    "        # Training\n",
    "        parallel_model.train()\n",
    "        for i, (local_batch, local_labels) in enumerate(train_dataloader):\n",
    "            global_step = global_step + 1\n",
    "\n",
    "            if cold_start and epoch < warmup_epochs:#linear scaling of the lr for warmup during the first few epochs\n",
    "                lr = final_lr * global_step / (warmup_epochs*len(train_dataset) / (batch_size * world_size))\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group['lr'] = lr\n",
    "\n",
    "            local_batch, targets = local_batch.to(device_ids[0]), local_labels.to(device_ids[0])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            answer, activation_loss = parallel_model(local_batch.type(torch.float32))\n",
    "\n",
    "            loss = lossFunc(answer, targets) + activation_loss * 2e-3\n",
    "\n",
    "            #Calc accuracy\n",
    "            answerSoftmax = softmax(answer)\n",
    "            maxIndex = answerSoftmax.argmax(dim=1)\n",
    "\n",
    "            correct = maxIndex.eq(targets)\n",
    "            accuracy = correct.type(dtype=torch.float16).mean(dim=0)\n",
    "            acc.append(accuracy)\n",
    "            \n",
    "            #Training step\n",
    "            if use_mixed_precision:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss: #Mixed precision\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "\n",
    "            grad_norm = torch.nn.utils.clip_grad_norm_(parallel_model.parameters(), 1e1)\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 50 == 0 and rank == 0:\n",
    "                print(\"epoch \" + str(epoch) + \" batch \" + str(i))\n",
    "                print(\"loss\", loss)\n",
    "                print(\"activation loss\", activation_loss)\n",
    "                print(grad_norm)\n",
    "\n",
    "            #logging and saving weights\n",
    "            if i % 1000 == 999:\n",
    "                trainAcc = sum(acc) / len(acc)\n",
    "                acc = []\n",
    "                print('Training accuracy: ' + str(trainAcc.item()))\n",
    "                if rank == 0:\n",
    "                    if weights_filename is not None:\n",
    "                        torch.save(base_model.state_dict(), weights_filename)\n",
    "                        print('Weights saved')\n",
    "\n",
    "                    summary = sess.run(train_acc_summary, feed_dict={train_acc_placeholder: trainAcc.item()})\n",
    "                    writer.add_summary(summary, global_step=global_step)  \n",
    "\n",
    "        if cold_start and weights_filename is not None and epoch % 10 == 0 and rank == 0:\n",
    "            torch.save(base_model.state_dict(), weights_filename + \"_cp\" + str(epoch))\n",
    "            print('Checkpoint saved')\n",
    "\n",
    "\n",
    "    cleanup()\n",
    "\n",
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    torch.distributed.init_process_group(\"nccl\", rank=rank, world_size=world_size)\n",
    "\n",
    "    # Explicitly setting seed to make sure that models created in two processes\n",
    "    # start from same random weights and biases.\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "def cleanup():\n",
    "    torch.distributed.destroy_process_group()\n",
    "\n",
    "def run(world_size):\n",
    "    torch.multiprocessing.spawn(worker_fn, args=(world_size,), nprocs=world_size, join=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run(4)#4 GPUs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os, sys\n",
    "import re\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "\n",
    "#tensorboard for accuracy graphs\n",
    "import tensorflow as tf\n",
    "\n",
    "def getCombinations(inputTensor, N, c, d):#input shape=(batch_size, obj_count, obj_dim) #batch_size=N, obj_count=c, obj_dim=d\n",
    "    tensorA = inputTensor.reshape(N, 1, c, d).expand(N, c, c, d)\n",
    "    tensorB = tensorA.transpose(1, 2)\n",
    "\n",
    "    return torch.cat((tensorB, tensorA), 3)\n",
    "\n",
    "devices = (torch.device(\"cuda:0\"), torch.device(\"cuda:1\"), torch.device(\"cuda:2\"), torch.device(\"cuda:3\"))\n",
    "\n",
    "if len(sys.argv) < 2:\n",
    "    print(\"Missing data path!\")\n",
    "    exit()\n",
    "\n",
    "dataset_name = 'neutral'#'interpolation'#'extrapolation'\n",
    "datapath = os.path.join(sys.argv[1],dataset_name)\n",
    "\n",
    "class PgmDataset(Dataset):\n",
    "    def __init__(self, filenames):\n",
    "        'Initialization'\n",
    "        self.filenames = filenames\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        filename = self.filenames[index]\n",
    "        with np.load(os.path.join(datapath, filename)) as data:\n",
    "            image = data['image'].astype(np.uint8).reshape(16, 160, 160)[:,::2,::2]\n",
    "            target = data['target']\n",
    "            meta = data['relation_structure']\n",
    "        return image, target, meta\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    images, targets, metas = zip(*batch)\n",
    "    images = torch.stack([torch.from_numpy(b) for b in images], 0)\n",
    "    targets = torch.stack([torch.from_numpy(b) for b in targets], 0)\n",
    "    return images, targets, metas\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "all_data = os.listdir(datapath)\n",
    "test_filenames = [p for p in all_data if re.match(r'^PGM_' + re.escape(dataset_name) + r'_test_(\\d+)\\.npz$', p) is not None]\n",
    "test_dataloader = DataLoader(PgmDataset(test_filenames), batch_size=batch_size, shuffle=False, num_workers=16, pin_memory=True, collate_fn=custom_collate_fn)\n",
    "\n",
    "class WReN(torch.nn.Module):\n",
    "    def __init__(self, m):\n",
    "        super(WReN, self).__init__()\n",
    "        self.relation_network_depth = m\n",
    "\n",
    "        self.g_dim = 512\n",
    "        self.h_dim = 256\n",
    "        self.f_dim = 256\n",
    "\n",
    "        self.use_mag_enc = True #switch between scalar input and magnitude encoded input\n",
    "        self.mag_enc_type_relu = False #switch between gaussian magnitude encoding and relu based magnitude encoding\n",
    "\n",
    "        self.magnitude_encoding_dim = 20\n",
    "        #model\n",
    "        #magnitude encoding\n",
    "        self.input_scale = 2.0/255.0\n",
    "        self.input_offset = -1.0\n",
    "        #self.input_encoding_variance_inv = torch.nn.Parameter(torch.tensor(self.magnitude_encoding_dim * 0.5))\n",
    "        std_dev = 0.28\n",
    "        self.input_encoding_variance_inv = 1.0 / (math.sqrt(2.0) * std_dev)\n",
    "        #self.normalization_factor = torch.nn.Parameter(torch.tensor(1.0 / (math.sqrt(2*math.pi) * std_dev)))\n",
    "        self.normalization_factor = 1.0 / (math.sqrt(2*math.pi) * std_dev)\n",
    "        self.mag_scale = torch.nn.Parameter(torch.linspace(-1.0, 1.0, steps=self.magnitude_encoding_dim), requires_grad=False)\n",
    "\n",
    "        if self.use_mag_enc:\n",
    "            conv_input_dim = self.magnitude_encoding_dim\n",
    "        else:\n",
    "            conv_input_dim = 1\n",
    "\n",
    "        self.conv = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(conv_input_dim, 32, 3, stride=2), \n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=2), \n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=2), \n",
    "            torch.nn.LeakyReLU(),\n",
    "            torch.nn.Conv2d(32, 32, 3, stride=2), \n",
    "            torch.nn.LeakyReLU()\n",
    "        )\n",
    "        self.post_cnn_linear = torch.nn.Linear(32*4*4, 256-9)#input = 32 feature maps with 4x4 resolution\n",
    "\n",
    "        self.tag_matrix = torch.nn.Parameter(torch.eye(9).repeat(8, 1), requires_grad=False)\n",
    "\n",
    "        self.g = torch.nn.Sequential(\n",
    "                torch.nn.Linear(2*256, self.g_dim), \n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(self.g_dim, self.g_dim), \n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(self.g_dim, self.g_dim), \n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(self.g_dim, self.h_dim),\n",
    "                torch.nn.LeakyReLU()\n",
    "            )\n",
    "\n",
    "        h = []\n",
    "        for i in range(m):\n",
    "            rel_layer_func = torch.nn.Sequential(\n",
    "                torch.nn.Linear(2*self.h_dim, self.h_dim), \n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(self.h_dim, self.h_dim), \n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(self.h_dim, self.h_dim), \n",
    "                torch.nn.LeakyReLU()\n",
    "            )\n",
    "            h.append(rel_layer_func)\n",
    "\n",
    "        self.h = torch.nn.ModuleList(h)\n",
    "\n",
    "        f_in_dim = self.h_dim\n",
    "        self.f = torch.nn.Sequential(\n",
    "                torch.nn.Linear(f_in_dim, self.f_dim), \n",
    "                torch.nn.LeakyReLU(),\n",
    "                torch.nn.Linear(self.f_dim, self.f_dim), \n",
    "                torch.nn.LeakyReLU()\n",
    "            )\n",
    "\n",
    "        self.f_final = torch.nn.Linear(self.f_dim, 1)\n",
    "        \n",
    "\n",
    "    def forward(self, batch):\n",
    "        batch_size = batch.size()[0]\n",
    "        #Panel preprocessor CNN\n",
    "        batch_flat = batch.reshape(batch_size*16, 1, 80, 80)#16 images per sample: 8 for context + 8 answer options\n",
    "\n",
    "        if self.use_mag_enc:\n",
    "            with torch.no_grad():\n",
    "                #magnitude encoding\n",
    "                batch_flat = batch_flat.transpose(1, 3)\n",
    "                if self.mag_enc_type_relu:\n",
    "                    #first order\n",
    "                    batch_flat = batch_flat.add_(255/self.magnitude_encoding_dim)\n",
    "                    batch_flat = torch.nn.functional.relu_(batch_flat.mul_(self.input_scale).add_(self.input_offset).add(-self.mag_scale))\n",
    "                    #second order\n",
    "                    batch_flat = torch.cat((batch_flat[:, :, :, :-1] - 2*batch_flat[:, :, :, 1:], batch_flat[:, :, :, -1].unsqueeze(dim=-1)), dim=-1).mul_(self.magnitude_encoding_dim/2)\n",
    "                    batch_flat = torch.nn.functional.relu_(batch_flat)\n",
    "                else:\n",
    "                    batch_flat = batch_flat.mul_(self.input_scale).add_(self.input_offset).tanh_().add(self.mag_scale).mul_(self.input_encoding_variance_inv).pow_(2).mul_(-1).exp_().mul_(self.normalization_factor)\n",
    "                batch_flat = batch_flat.transpose(3, 1)\n",
    "\n",
    "        conv_out = self.conv(batch_flat)\n",
    "        #scatter context\n",
    "        objectsWithoutPos = self.post_cnn_linear(conv_out.reshape(batch_size*16, -1))\n",
    "        panel_vectors = objectsWithoutPos.reshape(batch_size, 16, 256-9)\n",
    "        given, option1, option2, option3, option4, option5, option6, option7, option8 = panel_vectors.split((8, 1, 1, 1, 1, 1, 1, 1, 1), dim=1)\n",
    "        optionsWithContext = torch.cat((\n",
    "            given, option1, \n",
    "            given, option2, \n",
    "            given, option3, \n",
    "            given, option4, \n",
    "            given, option5, \n",
    "            given, option6, \n",
    "            given, option7, \n",
    "            given, option8\n",
    "        ), 1)\n",
    "        optionsWithoutPos = optionsWithContext.reshape(batch_size*8*9, 256-9)\n",
    "\n",
    "        objects = torch.cat((optionsWithoutPos, self.tag_matrix.repeat(batch_size, 1)), dim=1).reshape(batch_size*8, 9, 256-9+9)#8 answers to score per sample, 9 images (8 from context + 1 from answer) per answer option\n",
    "\n",
    "        #MLRN\n",
    "        objPairs2D = getCombinations(objects, batch_size*8, 9, 256)\n",
    "        objPairs = objPairs2D.reshape(batch_size*8*(9*9), 2*256)\n",
    "\n",
    "        gResult = self.g(objPairs)#apply MLP\n",
    "\n",
    "        prev_result = gResult\n",
    "        prev_dim = self.h_dim\n",
    "        prev_result_2d = prev_result.reshape(batch_size*8, 9, 9, prev_dim)\n",
    "        sum_j = prev_result_2d.sum(dim=2)\n",
    "        for i, h_layer in enumerate(self.h):\n",
    "            intermed_obj_pairs_2d = getCombinations(sum_j, batch_size*8, 9, prev_dim)\n",
    "            intermed_obj_pairs = intermed_obj_pairs_2d.reshape(batch_size*8*(9*9), 2*prev_dim)\n",
    "            prev_result = h_layer(intermed_obj_pairs)#apply MLP\n",
    "            prev_dim = self.h_dim\n",
    "            prev_result_2d = prev_result.reshape(batch_size*8, 9, 9, prev_dim)\n",
    "            sum_j = prev_result_2d.sum(dim=2)\n",
    "\n",
    "        hSum = sum_j.sum(dim=1)\n",
    "        result = self.f_final(self.f(hSum))#pre-softmax scores for every possible answer\n",
    "\n",
    "        answer = result.reshape(batch_size, 8)#scores of the 8 possible answers for every sample\n",
    "\n",
    "        activation_loss = hSum.pow(2).mean() + result.pow(2).mean()\n",
    "\n",
    "        return answer, activation_loss\n",
    "\n",
    "model = WReN(2).to(devices[0]) #3-layer MLRN\n",
    "\n",
    "if os.path.isfile(\"./weights.pt\"):\n",
    "    model.load_state_dict(torch.load(\"weights.pt\"))\n",
    "    print('Weights loaded')\n",
    "else:\n",
    "    print('No weights found')\n",
    "    exit()\n",
    "\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=1)\n",
    "\n",
    "parallel_model = torch.nn.DataParallel(model, device_ids=devices)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_acc = []\n",
    "objTypes = {}\n",
    "attrTypes = {}\n",
    "relTypes = {}\n",
    "single_rel_correct = 0\n",
    "single_rel_total = 0\n",
    "# Testing\n",
    "with torch.no_grad():\n",
    "    for i, (local_batch, local_labels, meta) in enumerate(test_dataloader):\n",
    "        local_batch, targets = local_batch.to(devices[0]), local_labels.to(devices[0])\n",
    "\n",
    "        answer, _ = parallel_model(local_batch.type(torch.float32))\n",
    "\n",
    "        #Calc accuracy\n",
    "        answerSoftmax = softmax(answer)\n",
    "        maxIndex = answerSoftmax.argmax(dim=1)\n",
    "\n",
    "        correct = maxIndex.eq(targets)\n",
    "        accuracy = correct.type(dtype=torch.float32).mean(dim=0)\n",
    "        test_acc.append(accuracy)\n",
    "\n",
    "        for j, jCorrect in enumerate(correct):\n",
    "            jCorrect = jCorrect.item()\n",
    "            if len(meta[j]) == 1:\n",
    "                single_rel_total += 1\n",
    "                if jCorrect == 1:\n",
    "                    single_rel_correct += 1\n",
    "                objType = meta[j][0][0]\n",
    "                if objType in objTypes:\n",
    "                    objTypes[objType]['total'] += 1\n",
    "                    if jCorrect == 1:\n",
    "                        objTypes[objType]['correct'] += 1\n",
    "                else:\n",
    "                    objTypes[objType] = {'total': 1, 'correct': jCorrect}\n",
    "\n",
    "                attrType = meta[j][0][1]\n",
    "                if attrType in attrTypes:\n",
    "                    attrTypes[attrType]['total'] += 1\n",
    "                    if jCorrect == 1:\n",
    "                        attrTypes[attrType]['correct'] += 1\n",
    "                else:\n",
    "                    attrTypes[attrType] = {'total': 1, 'correct': jCorrect}\n",
    "\n",
    "                relType = meta[j][0][2]\n",
    "                if relType in relTypes:\n",
    "                    relTypes[relType]['total'] += 1\n",
    "                    if jCorrect == 1:\n",
    "                        relTypes[relType]['correct'] += 1\n",
    "                else:\n",
    "                    relTypes[relType] = {'total': 1, 'correct': jCorrect}\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            print(\"batch \" + str(i))\n",
    "\n",
    "    for key in objTypes:\n",
    "        print(str(key) + ' ' + str(100 * objTypes[key]['correct'] / objTypes[key]['total']))\n",
    "    for key in attrTypes:\n",
    "        print(str(key) + ' ' + str(100 * attrTypes[key]['correct'] / attrTypes[key]['total']))\n",
    "    for key in relTypes:\n",
    "        print(str(key) + ' ' + str(100 * relTypes[key]['correct'] / relTypes[key]['total']))\n",
    "    print(str(objTypes))\n",
    "    print(str(attrTypes))\n",
    "    print(str(relTypes))\n",
    "\n",
    "    print('All single relations accuracy: ' + str(100 * single_rel_correct / single_rel_total))\n",
    "\n",
    "    total_test_acc = sum(test_acc) / len(test_acc)\n",
    "    print(sum(test_acc))\n",
    "    print(len(test_acc))\n",
    "    print('Test accuracy: ' + str(total_test_acc.item()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
